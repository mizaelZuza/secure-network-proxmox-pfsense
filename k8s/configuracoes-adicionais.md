# Guia de ConfiguraÃ§Ãµes Adicionais do Kubernetes

Este arquivo centraliza configuraÃ§Ãµes detalhadas e explicaÃ§Ãµes aprofundadas que complementam o guia principal de instalaÃ§Ã£o do cluster (`setup-kubernetes.md`).

## ğŸ“‹ SumÃ¡rio
1. [Entendendo MÃ³dulos do Kernel e Rede no Kubernetes](#mÃ³dulos-do-kernel-e-rede-no-kubernetes)
2. [ConfiguraÃ§Ã£o de NAT no pfSense para a Rede Kubernetes](#configuraÃ§Ã£o-de-nat-no-pfsense-para-kubernetes)
3. [ConfiguraÃ§Ã£o HAProxy para Kubernetes Dashboard](#configuraÃ§Ã£o-haproxy-para-kubernetes-dashboard)

---

## ğŸ§  Entendendo MÃ³dulos do Kernel e Rede no Kubernetes {#mÃ³dulos-do-kernel-e-rede-no-kubernetes}

### ğŸ“š Ãndice
- [VisÃ£o Geral](#visÃ£o-geral)
- [MÃ³dulo overlay](#mÃ³dulo-overlay)
- [MÃ³dulo br_netfilter](#mÃ³dulo-br_netfilter)
- [ParÃ¢metros sysctl](#parÃ¢metros-sysctl)
- [Onde Aplicar as ConfiguraÃ§Ãµes](#onde-aplicar-as-configuraÃ§Ãµes)
- [ConfiguraÃ§Ã£o de /etc/hosts](#configuraÃ§Ã£o-de-etchosts)
- [VerificaÃ§Ã£o e Troubleshooting](#verificaÃ§Ã£o-e-troubleshooting)

---

### ğŸ¯ VisÃ£o Geral

Este documento explica **por que** os mÃ³dulos do kernel `overlay` e `br_netfilter` sÃ£o necessÃ¡rios para o funcionamento do Kubernetes, e **onde** cada configuraÃ§Ã£o deve ser aplicada na sua infraestrutura.

#### Arquitetura da Infraestrutura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PfSense   â”‚ (192.168.3.1)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ VIP: 192.168.3.10 (Keepalived) 
       â”‚         â†“
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚ HAProxy + Keepalived   â”‚
       â”‚    â”‚ - LB-01: 192.168.3.11  â”‚
       â”‚    â”‚ - LB-02: 192.168.3.12  â”‚
       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚                              â”‚
       â”‚    â”‚      Control Planes          â”‚
       â”‚    â”‚  - CP-01: 192.168.3.21       â”‚
       â”‚    â”‚  - CP-02: 192.168.3.22       â”‚
       â”‚    â”‚  - CP-03: 192.168.3.23       â”‚
       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚                    â”‚
       â”‚    â”‚      Workers       â”‚
       â”‚    â”‚  - W-01: 192.168.3.31  â”‚
       â”‚    â”‚  - W-02: 192.168.3.32  â”‚
       â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€
```

---

### ğŸ“¦ MÃ³dulo `overlay`

#### O que Ã©?

O `overlay` Ã© um driver de filesystem que permite criar camadas (layers) de sistemas de arquivos sobrepostos.

#### Por que Ã© necessÃ¡rio?

**Containers usam imagens em camadas:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Container em execuÃ§Ã£o               â”‚  â† Camada READ/WRITE
â”‚  (camada gravÃ¡vel - ephemeral)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Suas configuraÃ§Ãµes personalizadas   â”‚  â† Camada READ-ONLY
â”‚  (ex: nginx.conf, scripts)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  InstalaÃ§Ã£o do Nginx                 â”‚  â† Camada READ-ONLY
â”‚  (binÃ¡rios, bibliotecas)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Imagem base Ubuntu                  â”‚  â† Camada READ-ONLY
â”‚  (sistema operacional mÃ­nimo)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Como funciona:**

1. **EficiÃªncia de armazenamento**: MÃºltiplos containers podem compartilhar as mesmas camadas base
2. **Rapidez**: NÃ£o precisa copiar toda a imagem para criar um container
3. **Isolamento**: Cada container tem sua prÃ³pria camada gravÃ¡vel

#### Exemplo PrÃ¡tico

```bash
# Sem overlay - NÃƒO FUNCIONA
sudo modprobe -r overlay
sudo docker run nginx
# Erro: "overlay2 not found"

# Com overlay - FUNCIONA
sudo modprobe overlay
sudo docker run nginx
# Container inicia normalmente âœ…
```

#### Alternativas (nÃ£o recomendadas)

- `aufs` - Antigo, descontinuado
- `devicemapper` - Lento, problemas de performance
- `btrfs` - Requer filesystem btrfs especÃ­fico

---

### ğŸŒ‰ MÃ³dulo `br_netfilter`

#### O que Ã©?

Permite que o **iptables** (firewall do Linux) processe trÃ¡fego que passa por **bridges de rede** (network bridges).

#### Por que Ã© CRÃTICO para Kubernetes?

##### Arquitetura de Rede do Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   NODE 1                        â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Pod A   â”‚       â”‚  Pod B   â”‚              â”‚
â”‚  â”‚10.244.1.5â”‚       â”‚10.244.1.6â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚                  â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚              â”‚                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚  cni0   â”‚  â† Bridge Virtual         â”‚
â”‚         â”‚ bridge  â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                            â”‚
â”‚              â”‚                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚  eth0   â”‚  â† Interface FÃ­sica       â”‚
â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        Rede FÃ­sica â†’ Outros Nodes
```

##### O Problema SEM `br_netfilter`

Quando um pacote passa pela bridge (`cni0`), ele **ignora** o iptables e vai direto para a rede fÃ­sica.

**ConsequÃªncias:**

1. âŒ **Services nÃ£o funcionam** - O kube-proxy nÃ£o consegue fazer load balancing
2. âŒ **Network Policies sÃ£o ignoradas** - Regras de firewall entre pods falham
3. âŒ **NAT nÃ£o funciona** - ComunicaÃ§Ã£o entre nodes quebra
4. âŒ **ClusterIP nÃ£o resolve** - RequisiÃ§Ãµes para Services falham

##### Fluxo de uma requisiÃ§Ã£o HTTP para um Service

**COM `br_netfilter` habilitado:**

```
1. Cliente faz request para: http://my-service.default.svc.cluster.local
   (DNS resolve para ClusterIP: 10.96.0.10)

2. Pacote chega na bridge cni0 do node
   â”‚
   â–¼
3. br_netfilter PERMITE que iptables intercepte o pacote âœ…
   â”‚
   â–¼
4. iptables (regras do kube-proxy) fazem DNAT:
   10.96.0.10 â†’ 10.244.1.5 (IP real do Pod)
   â”‚
   â–¼
5. Pacote Ã© roteado atravÃ©s do overlay network para o node correto
   â”‚
   â–¼
6. Chega no Pod destino âœ…
```

**SEM `br_netfilter`:**

```
1. Cliente faz request para: http://my-service.default.svc.cluster.local
   (DNS resolve para ClusterIP: 10.96.0.10)

2. Pacote chega na bridge cni0 do node
   â”‚
   â–¼
3. Pacote PASSA DIRETO pela bridge, ignorando iptables âŒ
   â”‚
   â–¼
4. Pacote sai pela eth0 com destino 10.96.0.10
   â”‚
   â–¼
5. âŒ FALHA - IP 10.96.0.10 nÃ£o existe fisicamente na rede
```

#### Como o kube-proxy usa iptables

O kube-proxy cria regras como estas:

```bash
# Ver regras criadas pelo kube-proxy
sudo iptables -t nat -L -n | grep KUBE

# Exemplo de regra para um Service:
-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m tcp --dport 80 \
   -j KUBE-SVC-XXXXXXXXXXX

# Esta regra faz DNAT (Destination NAT):
# 10.96.0.10:80 â†’ 10.244.1.5:8080 (Pod real)
```

**Sem `br_netfilter`, essas regras sÃ£o ignoradas para trÃ¡fego bridged!**

---

### âš™ï¸ ParÃ¢metros sysctl

#### `net.bridge.bridge-nf-call-iptables = 1`

**O que faz:**
- Ativa o processamento de pacotes IPv4 que passam por bridges atravÃ©s do iptables

**Por que Ã© necessÃ¡rio:**
- Mesmo com o mÃ³dulo `br_netfilter` carregado, o kernel precisa ser **explicitamente instruÃ­do** a chamar o iptables
- `= 1` significa "sim, processe trÃ¡fego de bridge pelo iptables"
- `= 0` significaria "ignore iptables para trÃ¡fego de bridge"

#### `net.bridge.bridge-nf-call-ip6tables = 1`

**O que faz:**
- Mesma funÃ§Ã£o que acima, mas para IPv6

**Por que Ã© necessÃ¡rio:**
- Kubernetes suporta dual-stack (IPv4 + IPv6)
- Garante que regras de firewall funcionem para ambos os protocolos

#### `net.ipv4.ip_forward = 1`

**O que faz:**
- Permite que o Linux **roteie pacotes** entre interfaces de rede

**Por que Ã© necessÃ¡rio:**
- Transforma o node em um mini-roteador
- Permite que pacotes destinados a outros nodes sejam **encaminhados** ao invÃ©s de **descartados**
- Essencial para comunicaÃ§Ã£o Pod-to-Pod entre nodes diferentes

**Exemplo:**

```bash
# SEM ip_forward (= 0)
Pod-A (Node1) â†’ tenta enviar pacote â†’ Pod-B (Node2)
âŒ Node1 descarta o pacote: "nÃ£o Ã© para mim e nÃ£o posso rotear"

# COM ip_forward (= 1)
Pod-A (Node1) â†’ tenta enviar pacote â†’ Pod-B (Node2)
âœ… Node1 encaminha o pacote: "nÃ£o Ã© para mim, mas vou rotear para Node2"
```

---

### ğŸ¯ Onde Aplicar as ConfiguraÃ§Ãµes

#### Tabela de Componentes

| Componente | MÃ³dulos Kernel | ParÃ¢metros sysctl | kubelet | /etc/hosts |
|------------|----------------|-------------------|---------|------------|
| **Control Planes (3x)** | âœ… Sim | âœ… Sim | âœ… Sim | âœ… Sim |
| **Workers (2x)** | âœ… Sim | âœ… Sim | âœ… Sim | âœ… Sim |
| **Load Balancers (2x)** | âŒ NÃ£o | âŒ NÃ£o | âŒ NÃ£o | ğŸŸ¡ Opcional |
| **PfSense** | âŒ NÃ£o | âŒ NÃ£o | âŒ NÃ£o | ğŸŸ¡ Opcional |

#### Por que NÃƒO nos Load Balancers?

**Load Balancers (HAProxy + Keepalived) nÃ£o fazem parte do cluster Kubernetes:**

- NÃ£o executam Pods
- NÃ£o precisam de container runtime
- NÃ£o precisam de mÃ³dulos overlay/br_netfilter
- Apenas balanceiam trÃ¡fego TCP na camada 4 (L4)

**O que eles precisam:**

```bash
# Apenas HAProxy e Keepalived
sudo apt install -y haproxy keepalived

# Configurar HAProxy para balancear API Server (porta 6443)
# Configurar Keepalived para fornecer VIP (alta disponibilidade)
```

---

### ğŸ“ ConfiguraÃ§Ã£o de /etc/hosts

#### âŒ Erro Comum

```bash
# ERRADO - nomes inconsistentes com hostname real
192.168.3.21    k8s-master01
192.168.3.22    k8s-control-plane-02
192.168.3.31    worker-node-1
```

**Problema:** O Kubernetes usa o **hostname real** da VM para identificar nodes. Se houver inconsistÃªncia, vocÃª terÃ¡:
- Nodes com nomes duplicados
- Certificados TLS invÃ¡lidos
- Dificuldade para identificar nodes no `kubectl get nodes`

#### âœ… ConfiguraÃ§Ã£o Correta

**Regra de ouro:** O primeiro nome apÃ³s o IP deve ser o **hostname real** da VM (retornado pelo comando `hostname`)

```bash
# Verificar hostname em cada VM
hostname
# SaÃ­da esperada: control-plane-01

hostnamectl
# Status completo do hostname
```

#### Modelo para todas as VMs

```bash
sudo nano /etc/hosts
```

```bash
# Loopback
127.0.0.1       localhost
127.0.1.1       control-plane-01    # â† AJUSTAR em cada VM (hostname local)

# Infraestrutura
192.168.3.1     pfsense
192.168.3.10    vip-k8s-api         # VIP do Keepalived

# Load Balancers
192.168.3.11    lb-node01
192.168.3.12    lb-node02

# Control Planes (usar hostname REAL de cada VM)
192.168.3.21    control-plane-01
192.168.3.22    control-plane-02
192.168.3.23    control-plane-03

# Workers (usar hostname REAL de cada VM)
192.168.3.31    worker-01
192.168.3.32    worker-02
```

#### Checklist de ConsistÃªncia

Execute em **cada VM**:

```bash
# 1. Verificar hostname atual
hostname

# 2. Verificar /etc/hostname
cat /etc/hostname

# 3. Se necessÃ¡rio, ajustar hostname
sudo hostnamectl set-hostname control-plane-01

# 4. Reiniciar para garantir
sudo reboot

# 5. ApÃ³s reboot, verificar novamente
hostname
hostnamectl

# 6. Editar /etc/hosts conforme modelo acima
sudo nano /etc/hosts
```

#### ImportÃ¢ncia para Kubernetes

Quando vocÃª executa `kubectl get nodes`, o resultado serÃ¡:

```bash
NAME                STATUS   ROLE           AGE     VERSION
control-plane-01    Ready    control-plane  5m      v1.28.0
control-plane-02    Ready    control-plane  4m      v1.28.0
control-plane-03    Ready    control-plane  3m      v1.28.0
worker-01           Ready    <none>         2m      v1.28.0
worker-02           Ready    <none>         1m      v1.28.0
```

Os nomes que aparecem aqui sÃ£o os **hostnames** das VMs, nÃ£o os nomes do `/etc/hosts`. Por isso a consistÃªncia Ã© crÃ­tica!

---

### ğŸ” VerificaÃ§Ã£o e Troubleshooting

#### Verificar mÃ³dulos carregados

```bash
# Verificar se mÃ³dulos estÃ£o carregados
lsmod | grep overlay
lsmod | grep br_netfilter

# SaÃ­da esperada:
# overlay    212992  1
# br_netfilter  32768  0
# bridge    421888  1 br_netfilter
```

#### Verificar parÃ¢metros sysctl

```bash
# Verificar cada parÃ¢metro
sysctl net.bridge.bridge-nf-call-iptables
sysctl net.bridge.bridge-nf-call-ip6tables
sysctl net.ipv4.ip_forward

# SaÃ­da esperada (todos = 1):
# net.bridge.bridge-nf-call-iptables = 1
# net.bridge.bridge-nf-call-ip6tables = 1
# net.ipv4.ip_forward = 1
```

#### Verificar configuraÃ§Ã£o completa

```bash
# Mostrar tudo de uma vez
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

#### Testar conectividade

```bash
# Ping entre nodes usando hostname
ping control-plane-01
ping worker-01

# Testar resoluÃ§Ã£o de nomes
getent hosts control-plane-01

# Verificar se VIP estÃ¡ acessÃ­vel
ping vip-k8s-api
curl -k https://vip-k8s-api:6443
```

#### Troubleshooting comum

##### Problema: Services nÃ£o funcionam

```bash
# Verificar se br_netfilter estÃ¡ ativo
lsmod | grep br_netfilter

# Verificar parÃ¢metros
sysctl net.bridge.bridge-nf-call-iptables
```

##### Problema: Pods nÃ£o conseguem se comunicar entre nodes

```bash
# Verificar ip_forward
sysctl net.ipv4.ip_forward

# Deve retornar: net.ipv4.ip_forward = 1
```

##### Problema: Container runtime nÃ£o inicia

```bash
# Verificar overlay
lsmod | grep overlay

# Verificar logs do containerd
sudo journalctl -u containerd -n 50
```

---

### ğŸ“š ReferÃªncias

- [DocumentaÃ§Ã£o Oficial Kubernetes - Prerequisites](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
- [Linux Bridge Documentation](https://wiki.linuxfoundation.org/networking/bridge)
- [OverlayFS Documentation](https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html)
- [Netfilter Documentation](https://www.netfilter.org/documentation/)

---
---

## ğŸ”¥ ConfiguraÃ§Ã£o de NAT no pfSense para Kubernetes {#configuraÃ§Ã£o-de-nat-no-pfsense-para-kubernetes}

### Problema Comum

ApÃ³s criar a interface LAN_K8S e configurar as regras de firewall, as VMs podem ter conectividade local (ping para o gateway), mas nÃ£o conseguem acessar a internet. Isso ocorre porque **falta configuraÃ§Ã£o de NAT (Network Address Translation)** para a nova rede.

### Sintomas

- âœ… Ping para o gateway (192.168.3.1) funciona
- âœ… Conectividade entre VMs da mesma rede funciona
- âŒ Ping para IPs externos (8.8.8.8, 1.1.1.1) falha
- âŒ ResoluÃ§Ã£o de DNS externa nÃ£o funciona
- âŒ Downloads e atualizaÃ§Ãµes (apt update) falham

### VerificaÃ§Ã£o do Problema

#### No pfSense, acesse:

**Firewall â†’ NAT â†’ Outbound**

Verifique o modo atual:
- Se estiver em **"Automatic outbound NAT rule generation"**, o problema nÃ£o Ã© NAT
- Se estiver em **"Manual Outbound NAT rule generation"** ou **"Hybrid Outbound NAT rule generation"**, verifique se existe regra para a rede 192.168.3.0/24

---


### SoluÃ§Ã£o 1: Modo AutomÃ¡tico (Recomendado para LaboratÃ³rio)

O modo automÃ¡tico cria regras de NAT automaticamente para todas as interfaces configuradas.

#### Passos:

1. Acesse: **Firewall â†’ NAT â†’ Outbound**

2. Selecione: **â¦¿ Automatic outbound NAT rule generation**

3. Clique em **Save**

4. Clique em **Apply Changes**

5. Verifique as regras criadas automaticamente na seÃ§Ã£o "Automatic Rules":
   ```
   âœ… WAN | 192.168.1.0/24 â†’ * | * | WAN address
   âœ… WAN | 192.168.2.0/24 â†’ * | * | WAN address
   âœ… WAN | 192.168.3.0/24 â†’ * | * | WAN address
   ```

#### Testar na VM:

```bash
ping -c 3 8.8.8.8
ping -c 3 google.com
curl -I https://google.com
```

---


### SoluÃ§Ã£o 2: Modo Manual (Para Controle Granular)

Use este modo se precisar de controle fino sobre quais redes podem ter NAT ou se quiser configuraÃ§Ãµes especÃ­ficas.

#### Passos:

1. Acesse: **Firewall â†’ NAT â†’ Outbound**

2. Se ainda nÃ£o estiver em modo manual, mude para:
   **â¦¿ Manual Outbound NAT rule generation**

3. Clique em **Save**

4. As regras existentes serÃ£o convertidas. Agora adicione a regra para LAN_K8S:

#### Adicionar Regra NAT para LAN_K8S:

1. Clique em **Add** â†‘ (adicionar no topo)

2. Configure:

**Interface:**
```
Interface: WAN
```

**Protocol:**
```
Address Family: IPv4
Protocol: Any
```

**Source:**
```
Source: Network
Network: 192.168.3.0 / 24
```

**Destination:**
```
Destination: Any
```

**Translation:**
```
Translation / Target: Interface Address
```

**Misc:**
```
Description: NAT LAN_K8S (Kubernetes) para WAN
Static Port: [ ] (desmarcado)
```

3. **Save**

4. **Apply Changes**

#### Ordem das Regras NAT:

ApÃ³s criar, suas regras devem ficar assim:

```
1. âœ… WAN | 192.168.3.0/24 â†’ * | * | WAN address | NAT LAN_K8S
2. âœ… WAN | 192.168.1.0/24 â†’ * | * | WAN address | NAT LAN Servidores
3. âœ… WAN | 192.168.2.0/24 â†’ * | * | WAN address | NAT LAN Clientes
4. âœ… WAN | 127.0.0.0/8 â†’ * | 500 (ISAKMP) | WAN address | (Regra ISAKMP)
5. âœ… WAN | 127.0.0.0/8 â†’ * | * | WAN address | (localhost)
```

---


### SoluÃ§Ã£o 3: Modo HÃ­brido (AutomÃ¡tico + Manual)

Este modo permite regras automÃ¡ticas E regras manuais adicionais.

#### Passos:

1. **Firewall â†’ NAT â†’ Outbound**

2. Selecione: **â¦¿ Hybrid Outbound NAT rule generation**

3. **Save â†’ Apply Changes**

4. Adicione regras manuais especÃ­ficas se necessÃ¡rio (mesmo processo da SoluÃ§Ã£o 2)

---


### ValidaÃ§Ã£o e Testes

#### Teste 1: Resetar estados de conexÃ£o

ApÃ³s configurar o NAT, limpe as conexÃµes antigas:

1. **Diagnostics â†’ States â†’ Reset States**
2. Marque: **Reset all states**
3. Clique em **Reset**

#### Teste 2: Verificar conectividade na VM

```bash
# Teste bÃ¡sico de rede
ping -c 3 192.168.3.1    # Gateway
ping -c 3 8.8.8.8        # Internet (Google DNS)
ping -c 3 1.1.1.1        # Internet (Cloudflare DNS)

# Teste de DNS
nslookup google.com
dig google.com

# Teste HTTP/HTTPS
curl -I http://google.com
curl -I https://google.com

# Teste de download
wget -O /dev/null http://speedtest.tele2.net/1MB.zip
```

#### Teste 3: Verificar IP pÃºblico visto pela VM

```bash
curl ifconfig.me
```

Deve retornar o **IP pÃºblico da sua WAN** (o mesmo que o pfSense usa para sair Ã  internet).

#### Teste 4: Verificar logs de NAT (opcional)

1. **Status â†’ System Logs â†’ Firewall**
2. Aba: **NAT**
3. Durante os testes, vocÃª verÃ¡ as traduÃ§Ãµes de endereÃ§o acontecendo

---


### Troubleshooting

#### Problema: NAT configurado mas internet nÃ£o funciona

**PossÃ­veis causas:**

1. **Regras de firewall bloqueando:**
   - Verifique **Firewall â†’ Rules â†’ LAN_K8S**
   - Deve ter regra **Pass** permitindo trÃ¡fego de `LAN_K8S net` para `Any`

2. **Gateway WAN offline:**
   - Verifique **System â†’ Routing â†’ Gateways**
   - Gateway WAN deve estar **Online** (bolinha verde)

3. **DNS nÃ£o configurado:**
   - Na VM: `cat /etc/resolv.conf`
   - Deve ter: `nameserver 192.168.3.1`

4. **Rota padrÃ£o ausente na VM:**
   ```bash
ip route show
   # Deve ter: default via 192.168.3.1
   ```

#### Problema: Apenas algumas VMs funcionam

- Verifique se todas as VMs estÃ£o na rede correta (192.168.3.0/24)
- Verifique se todas tÃªm o gateway configurado (192.168.3.1)
- Execute `sudo netplan apply` em cada VM

#### Problema: Internet lenta apÃ³s NAT

- **ProvÃ¡vel causa:** FragmentaÃ§Ã£o de pacotes
- **SoluÃ§Ã£o:** Ajustar MSS Clamping

**Firewall â†’ Rules â†’ LAN_K8S â†’ Regra de saÃ­da â†’ Advanced:**
```
Tag: (vazio)
Max state entries: (deixe padrÃ£o)
Max new connections: (deixe padrÃ£o)
State Type: Keep state
No XMLRPC Sync: [ ]
Schedule: (none)
Gateway: default (ou seu gateway WAN)
Advanced Options:
  Max MSS: 1420 (ajuste se necessÃ¡rio)
```

---


### Exemplo Completo de ConfiguraÃ§Ã£o

#### Resumo das configuraÃ§Ãµes necessÃ¡rias:

**1. Interface LAN_K8S configurada:**
- IP: 192.168.3.1/24
- Interface ativa

**2. Regras de Firewall (LAN_K8S):**
```
âœ… Pass | TCP/UDP | LAN_K8S net â†’ LAN_K8S address | Port 53 (DNS)
âœ… Pass | Any | LAN_K8S net â†’ LAN_K8S net (interno)
âœ… Pass | TCP | LAN_K8S net â†’ Any | Port 80,443 (web)
âœ… Pass | UDP | LAN_K8S net â†’ Any | Port 123 (NTP)
âœ… Pass | ICMP | LAN_K8S net â†’ Any (ping)
```

**3. NAT Outbound:**
```
âœ… Modo: Automatic (ou Manual com regra para 192.168.3.0/24)
âœ… Regra: WAN | 192.168.3.0/24 â†’ * | WAN address
```

**4. Routing:**
```
âœ… Gateway WAN: Online
âœ… Rota padrÃ£o configurada no pfSense
```

---


### Checklist de VerificaÃ§Ã£o

ApÃ³s configurar o NAT:

- [ ] NAT configurado (Automatic ou Manual com regra para 192.168.3.0/24)
- [ ] Estados de conexÃ£o resetados
- [ ] VM consegue pingar 192.168.3.1 (gateway)
- [ ] VM consegue pingar 8.8.8.8 (internet)
- [ ] VM consegue resolver DNS (nslookup google.com)
- [ ] VM consegue baixar da internet (curl/wget funcionando)
- [ ] IP pÃºblico visto pela VM Ã© o mesmo da WAN do pfSense

---


### Boas PrÃ¡ticas

1. **Use modo Automatic** para laboratÃ³rio/estudo (mais simples)
2. **Use modo Manual** para produÃ§Ã£o (mais controle)
3. **Documente** qualquer regra manual criada
4. **Teste apÃ³s cada mudanÃ§a** antes de prosseguir
5. **FaÃ§a backup** da configuraÃ§Ã£o do pfSense apÃ³s funcionar:
   - **Diagnostics â†’ Backup & Restore â†’ Backup Configuration**

---


### ReferÃªncias

- **pfSense NAT Documentation:** https://docs.netgate.com/pfsense/en/latest/nat/
- **Outbound NAT:** https://docs.netgate.com/pfsense/en/latest/nat/outbound.html

---
---

## ğŸš€ ConfiguraÃ§Ã£o HAProxy para Kubernetes Dashboard {#configuraÃ§Ã£o-haproxy-para-kubernetes-dashboard}

# Adicione ao final de /etc/haproxy/haproxy.cfg

#---------------------------------------------------------------------
# Frontend Dashboard Kubernetes (porta 8443)
#---------------------------------------------------------------------
frontend dashboard-frontend
    bind *:8443
    mode tcp
    option tcplog
    default_backend dashboard-backend

#---------------------------------------------------------------------
# Backend Dashboard com todos os nodes
#---------------------------------------------------------------------
backend dashboard-backend
    mode tcp
    option tcp-check
    balance roundrobin
    
    # Control Planes
    server cp01 192.168.3.21:30443 check fall 3 rise 2
    server cp02 192.168.3.22:30443 check fall 3 rise 2
    server cp03 192.168.3.23:30443 check fall 3 rise 2
    
    # Workers
    server w01  192.168.3.31:30443 check fall 3 rise 2
    server w02  192.168.3.32:30443 check fall 3 rise 2

#---------------------------------------------------------------------
# Opcional: EstatÃ­sticas do HAProxy
#---------------------------------------------------------------------
listen stats
    bind *:9000
    mode http
    stats enable
    stats uri /stats
    stats refresh 10s
    stats admin if TRUE
    stats auth admin:password  # Mude a senha!

